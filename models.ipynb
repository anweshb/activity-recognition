{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MultiHeadAttention, TimeDistributed, MaxPool2D, BatchNormalization, Dense, Input, Reshape, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'saved_np_data/'\n",
    "features_path = os.path.join(data_dir, 'features.npy')\n",
    "labels_path = os.path.join(data_dir, 'labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1113, 10, 100, 100, 3)\n",
      "(1113,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples = 1113\n",
    "## Sequence Size = 10\n",
    "## img_dim = (100, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (779, 10, 100, 100, 3)\n",
      "y_train shape: (779,)\n",
      "X_test shape: (334, 10, 100, 100, 3)\n",
      "y_test shape: (334,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(32, 3, activation = 'relu'), input_shape = (10,100,100,3)))\n",
    "# model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(64, 3, activation = 'relu')))\n",
    "# model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(128, 3, activation = 'relu')))\n",
    "# model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# num_heads = 8  # You can adjust the number of attention heads as needed\n",
    "# key_dim = 64  # Adjust the number of units for the attention mechanismx\n",
    "\n",
    "# attention_layer = MultiHeadAttention(key_dim=key_dim, num_heads=num_heads)\n",
    "\n",
    "# # Reshape the output from the previous layers to be 3D (batch_size * num_tokens, height * width, channels)\n",
    "# reshape_layer = TimeDistributed(Flatten())\n",
    "# attention_input = reshape_layer(model.layers[-1].output)\n",
    "\n",
    "# # Apply Multi-Head Attention\n",
    "# attention_output = attention_layer(attention_input, attention_input)\n",
    "# # model.add(Dense(6))\n",
    "\n",
    "\n",
    "input_shape = (10, 100, 100, 3)\n",
    "video_input = Input(shape=input_shape)\n",
    "\n",
    "# Feature Extraction using Conv2D layers with BatchNormalization\n",
    "x = TimeDistributed(Conv2D(32, 3, activation='relu'))(video_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = TimeDistributed(BatchNormalization())(x)\n",
    "\n",
    "x = TimeDistributed(Conv2D(64, 3, activation='relu'))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = TimeDistributed(BatchNormalization())(x)\n",
    "\n",
    "x = TimeDistributed(Conv2D(128, 3, activation='relu'))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = TimeDistributed(BatchNormalization())(x)\n",
    "\n",
    "# Reshape the output from the previous layers to be 3D (batch_size * num_tokens, height * width, channels)\n",
    "x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "# Multi-Head Attention for Temporal Feature Extraction\n",
    "num_heads = 8  # You can adjust the number of attention heads as needed\n",
    "key_dim = 64  # Adjust the number of units for the attention mechanism\n",
    "\n",
    "# Create the MultiHeadAttention layer\n",
    "attention_layer = MultiHeadAttention(key_dim=key_dim, num_heads=num_heads)\n",
    "\n",
    "# Reshape the output from the previous layers to be 3D (batch_size * num_tokens, height * width, channels)\n",
    "attention_input = Reshape((-1, x.shape[-1]))(x)\n",
    "\n",
    "# Apply Multi-Head Attention\n",
    "attention_output = attention_layer(attention_input, attention_input)\n",
    "\n",
    "x = Flatten()(attention_output)\n",
    "\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(7, activation = 'softmax')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=video_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 100, 10  0           []                               \n",
      "                                0, 3)]                                                            \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDistri  (None, 10, 98, 98,   896        ['input_2[0][0]']                \n",
      " buted)                         32)                                                               \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 10, 98, 98,   0           ['time_distributed_7[0][0]']     \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDistri  (None, 10, 98, 98,   128        ['dropout_4[0][0]']              \n",
      " buted)                         32)                                                               \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDistri  (None, 10, 96, 96,   18496      ['time_distributed_8[0][0]']     \n",
      " buted)                         64)                                                               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 10, 96, 96,   0           ['time_distributed_9[0][0]']     \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " time_distributed_10 (TimeDistr  (None, 10, 96, 96,   256        ['dropout_5[0][0]']              \n",
      " ibuted)                        64)                                                               \n",
      "                                                                                                  \n",
      " time_distributed_11 (TimeDistr  (None, 10, 94, 94,   73856      ['time_distributed_10[0][0]']    \n",
      " ibuted)                        128)                                                              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 10, 94, 94,   0           ['time_distributed_11[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " time_distributed_12 (TimeDistr  (None, 10, 94, 94,   512        ['dropout_6[0][0]']              \n",
      " ibuted)                        128)                                                              \n",
      "                                                                                                  \n",
      " time_distributed_13 (TimeDistr  (None, 10, 1131008)  0          ['time_distributed_12[0][0]']    \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 10, 1131008)  0           ['time_distributed_13[0][0]']    \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 10, 1131008)  2317436928  ['reshape_2[0][0]',             \n",
      " eadAttention)                                                    'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10, 512)      579076608   ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 10, 512)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10, 7)        3591        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,896,611,271\n",
      "Trainable params: 2,896,610,823\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.build(input_shape = (10,100,100,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
