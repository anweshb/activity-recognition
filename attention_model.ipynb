{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9f75872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MultiHeadAttention, TimeDistributed, MaxPool2D, BatchNormalization, Dense, Input, Reshape, Flatten, Add, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f973f5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (779, 10, 100, 100, 3)\n",
      "y_train shape: (779,)\n",
      "X_val shape: (100, 10, 100, 100, 3)\n",
      "y_val shape: (100,)\n",
      "X_test shape: (234, 10, 100, 100, 3)\n",
      "y_test shape: (234,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'saved_np_data/'\n",
    "features_path = os.path.join(data_dir, 'features.npy')\n",
    "labels_path = os.path.join(data_dir, 'labels.npy')\n",
    "\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size = 0.7)\n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483fdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatio_temporal_transformer_block(inputs, num_heads=8, key_dim=64, ff_dim=64, dropout_rate=0.1):\n",
    "    # LayerNormalization and Multi-Head Self-Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    attention_output_1 = MultiHeadAttention(\n",
    "        key_dim=key_dim, num_heads=num_heads, dropout=dropout_rate\n",
    "    )(x, x)\n",
    "    \n",
    "    # Residual Connection\n",
    "    attention_output_1 = Add()([inputs, attention_output_1])\n",
    "    \n",
    "    # Second LayerNormalization and Multi-Head Self-Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(attention_output_1)\n",
    "    attention_output_2 = MultiHeadAttention(\n",
    "        key_dim=key_dim, num_heads=num_heads, dropout=dropout_rate\n",
    "    )(x, x)\n",
    "    \n",
    "    # Residual Connection\n",
    "    attention_output_2 = Add()([attention_output_1, attention_output_2])\n",
    "    \n",
    "    # LayerNormalization and Feed Forward Network\n",
    "    x = LayerNormalization(epsilon=1e-6)(attention_output_2)\n",
    "    x = Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    \n",
    "    # Residual Connection\n",
    "    x = keras.layers.Add()([attention_output_2, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (10, 100, 100, 3)\n",
    "video_input = Input(shape=input_shape)\n",
    "\n",
    "# Spatial Feature Extraction using Conv2D layers with BatchNormalization\n",
    "x = TimeDistributed(Conv2D(32, 3, activation='relu'))(video_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = TimeDistributed(BatchNormalization())(x)\n",
    "\n",
    "x = TimeDistributed(Conv2D(64, 3, activation='relu'))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = TimeDistributed(BatchNormalization())(x)\n",
    "\n",
    "x = TimeDistributed(Conv2D(128, 3, activation='relu'))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = TimeDistributed(BatchNormalization())(x)\n",
    "\n",
    "# Reshape the output from the previous layers to be 3D (batch_size * num_tokens, height * width, channels)\n",
    "x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "# Multi-Head Attention for Temporal Feature Extraction\n",
    "num_heads = 8  \n",
    "key_dim = 64  \n",
    "\n",
    "# Create the MultiHeadAttention layer\n",
    "attention_layer = MultiHeadAttention(key_dim=key_dim, num_heads=num_heads)\n",
    "\n",
    "# Reshape the output from the previous layers to be 3D (batch_size * num_tokens, height * width, channels)\n",
    "attention_input = Reshape((-1, x.shape[-1]))(x)\n",
    "\n",
    "# Apply Multi-Head Attention\n",
    "attention_output = attention_layer(attention_input, attention_input)\n",
    "\n",
    "x = Flatten()(attention_output)\n",
    "\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(7, activation = 'softmax')(x) \n",
    "\n",
    "# model.summary()\n",
    "\n",
    "timestamp = time.time()\n",
    "datetime_obj = datetime.fromtimestamp(timestamp)\n",
    "fmt_time = datetime_obj.strftime('%m-%d %H:%M:%S')\n",
    "\n",
    "tb = TensorBoard(log_dir=f'logs/{fmt_time}')\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 15)\n",
    "\n",
    "ckpt = ModelCheckpoint(filepath = 'cpkts/model-{epoch:02d}-{val_loss:.4f}.hdf5',\n",
    "                      monitor = 'val_loss',\n",
    "                      mode = 'min',\n",
    "                      save_best_only = True,\n",
    "                      verbose = 1)\n",
    "\n",
    "\n",
    "strat = MirroredStrategy()\n",
    "\n",
    "with strat.scope():\n",
    "   \n",
    "    model = Model(inputs=video_input, outputs=output) \n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128 * strat.num_replicas_in_sync\n",
    "\n",
    "model.fit(X_train, y_train, validation_split = 0.2, batch_size = BATCH_SIZE, epochs = 5000, callbacks = [tb, es, ckpt])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
